{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tina\\Desktop\\DATS 6501 - Capstone Project - Tina Nguyen\\02. Data\\Sample Data\n",
      "['historical_data1_Q12013.txt', 'historical_data1_Q22013.txt', 'historical_data1_time_Q12013.txt', 'historical_data1_time_Q22013.txt']\n",
      "Performance data:  ['historical_data1_time_Q12013.txt', 'historical_data1_time_Q22013.txt']\n",
      "\n",
      "Origination data: ['historical_data1_Q12013.txt', 'historical_data1_Q22013.txt']\n",
      "Shape of performance data:  (4959, 1)\n",
      "        id_loan\n",
      "0  F113Q1000184\n",
      "1  F113Q1000219\n",
      "2  F113Q1000246\n",
      "3  F113Q1000289\n",
      "4  F113Q1000477\n",
      "Shape of origin data:  (184942, 24)\n",
      "\n",
      "Total loans funded:  184942\n",
      "\n",
      "Final df shape:  (184942, 29)\n",
      "Number of good and bad loans:  \n",
      " 0    183370\n",
      "1      1572\n",
      "Name: default, dtype: int64\n",
      "\n",
      "Total number of unique loans:  184942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# identify working directories\n",
    "DIR = os.path.join( os.path.dirname(os.getcwd()))\n",
    "DATA_DIR = os.path.join(DIR ,'02. Data')\n",
    "SAMPLE_DIR = DATA_DIR + '\\Sample Data'\n",
    "print(SAMPLE_DIR)\n",
    "print(os.listdir(SAMPLE_DIR))\n",
    "\n",
    "# SEPARATE PERFORMANCE AND TIME DATA INTO 2 DIFFERENT LISTS\n",
    "keyword = 'time'\n",
    "perf = []  # list containing all performance data - performance data has the word _time_\n",
    "orign = []  # list containing all origination data\n",
    "for f in os.listdir(SAMPLE_DIR):\n",
    "    if keyword in f:\n",
    "        perf.append(f)\n",
    "    else:\n",
    "        orign.append(f)\n",
    "\n",
    "print('Performance data: ',perf)\n",
    "print()\n",
    "print('Origination data:', orign)\n",
    "\n",
    "# PREPROCESS PERFORMANCE DATA\n",
    "performance = []\n",
    "for file in perf:\n",
    "    filename = os.path.join(SAMPLE_DIR, file)\n",
    "    perf_df = pd.read_csv(filename, sep=\"|\", usecols=[0,1,3], names=['id_loan', 'mthly_rpt', 'default'], skipinitialspace=True, error_bad_lines=False,\n",
    "                              index_col=False, dtype='unicode') # only select specific columns to save computing time\n",
    "    perf_df['default'] = perf_df['default'].replace('XX', np.NaN) # convert XX values in default column to NaN\n",
    "    perf_df['default'] = perf_df['default'].replace('R', np.NaN) # convert R values in default column to NaN\n",
    "    perf_df.dropna(inplace=True)\n",
    "    perf_df = perf_df[(perf_df['default'] != '0') & (perf_df['default'] != '1') & (perf_df['default'] != '2')]  # only select default > 3 (more than 90 days delinquent D90)\n",
    "    perf = pd.DataFrame(np.unique(perf_df['id_loan']), columns=['id_loan'])  # find unique id loan with the above criteria\n",
    "    performance.append(perf)\n",
    "\n",
    "master_perf = pd.concat(performance)  # a dataframe containing all loan ids with D90 or worse\n",
    "print('Shape of performance data: ', master_perf.shape)\n",
    "print(master_perf.head())\n",
    "\n",
    "# PREPROCESS ORIGINATION DATA\n",
    "origination = []\n",
    "for file in orign:\n",
    "    filename = os.path.join(SAMPLE_DIR, file)\n",
    "    orign_df = pd.read_csv(filename, sep=\"|\",\n",
    "                              names=['cr_scr', 'frst_pmt', 'frst_homebuyer', 'mtry_date', 'MSA', 'MI_pct', 'unit','occ_sts', 'cltv', 'dti','upb',\n",
    "                 'ltv','interest_rate', 'channel', 'ppm','pdt_type','ppty_state','ppty_type','pstl_code','id_loan','loan_prps',\n",
    "                 'term','total_borr','slr','srvc','cnfm_flag'], skipinitialspace=True, error_bad_lines=False,\n",
    "                              index_col=False, dtype='unicode') # import text files, include all data\n",
    "    # replace placeholder values with NaN and drop NaN\n",
    "    orign_df[['cr_scr', 'ltv', 'dti', 'interest_rate', 'cltv', 'MI_pct', 'upb']] = orign_df[['cr_scr', 'ltv', 'dti', 'interest_rate', 'cltv', 'MI_pct', 'upb']].astype('float64')\n",
    "    orign_df['cr_scr'] = [np.NaN if x == 9999 else x for x in (orign_df['cr_scr'].apply(lambda x: x))]\n",
    "    orign_df['frst_homebuyer'] = [np.NaN if x == '9' else x for x in (orign_df['frst_homebuyer'].apply(lambda x: x))]\n",
    "    orign_df['MI_pct'] = orign_df['MI_pct'].astype('int64')\n",
    "    orign_df['interest_rate'] = orign_df['interest_rate'].astype(float)\n",
    "    orign_df['MI_pct'] = [np.NaN if x == 999 else x for x in (orign_df['MI_pct'].apply(lambda x: x))]\n",
    "    orign_df['unit'] = [np.NaN if x == 99 else x for x in (orign_df['unit'].apply(lambda x: x))]\n",
    "    orign_df['occ_sts'] = [np.NaN if x == 9 else x for x in (orign_df['occ_sts'].apply(lambda x: x))]\n",
    "    orign_df['cltv'] = [np.NaN if x == 999 else x for x in (orign_df['cltv'].apply(lambda x: x))]\n",
    "    orign_df['dti'] = [np.NaN if (x == 9999 or x == 999) else x for x in (orign_df['dti'].apply(lambda x: x))]\n",
    "    orign_df['cnfm_flag'] = orign_df['cnfm_flag'].fillna('N')\n",
    "    orign_df.drop(['ppm', 'pdt_type'], axis=1,  inplace=True)\n",
    "    orign_df.dropna(inplace=True)\n",
    "    origination.append(orign_df)\n",
    "\n",
    "master_orign = pd.concat(origination) # dataframe with all origination data\n",
    "print('Shape of origin data: ', master_orign.shape)\n",
    "print()\n",
    "print('Total loans funded: ', master_orign.shape[0])\n",
    "print()\n",
    "\n",
    "# MASTER DATAFRAME PREPROCESSING\n",
    "master_df = master_perf.merge(master_orign, on='id_loan', how='outer', indicator=True)  # merge performing and origination data\n",
    "# drop all remanining NaN values\n",
    "master_df = master_df.dropna()\n",
    "\n",
    "# create year and Year+Quarter columns by extracting from columns loan id\n",
    "master_df['Year'] = ['20' + x for x in (master_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "master_df['YrQtr'] = ['20' + x for x in (master_df['id_loan'].apply(lambda x: x[2:6]))]\n",
    "# create a default column. Loans in both origination and D90 perf dataframes are delinquent. Loans only in origination are not delinquent\n",
    "master_df['default'] = master_df['_merge'].map({'both': 1, 'right_only': 0})\n",
    "\n",
    "# Merge w quarterly interest rate\n",
    "int_rate = pd.read_excel(os.path.join(DATA_DIR, '01. 30-fixed-rates.xlsx'), sheet_name='Qtr Avg')\n",
    "int_rate['Rate'] = int_rate['Rate'].astype(float)\n",
    "# print('Total rows for quarterly interest rate: ', int_rate.shape[0])\n",
    "master_df = master_df.merge(int_rate, on='YrQtr', how='left')\n",
    "print('Final df shape: ', master_df.shape)\n",
    "# create a variable to indicate the spread of interest rate at origination (30-year fixed-rate less rate of the loan)\n",
    "master_df['sato'] = master_df['Rate'] - master_df['interest_rate']\n",
    "print('Number of good and bad loans: ', '\\n', master_df['default'].value_counts()) # count delinquent vs good loans\n",
    "print()\n",
    "print('Total number of unique loans: ', len(np.unique(master_df['id_loan'])))\n",
    "\n",
    "# master_df.to_csv('C:/Users/tina/Desktop/Capstone/Data/d90_full_data.csv', index=False) (full dataset)\n",
    "\n",
    "master_df.to_csv(os.path.join(SAMPLE_DIR, 'sample.csv'), index=False) # generate sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
